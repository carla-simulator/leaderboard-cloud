apiVersion: batch/v1
kind: Job
metadata:
  name.$: $.submission.name
spec:
  backoffLimit: 8
  template:
    spec:
      serviceAccountName: submission-worker
      nodeSelector:
        node.kubernetes.io/instance-type.$: $.cluster.instance_type

      initContainers:
        - name: private-contents
          image.$: $.cluster.leaderboard_image
          command: ["/bin/bash", "-c"]
          args:
            - |
              cp -r ${LEADERBOARD_ROOT}/* /tmp/leaderboard/
              cp -r ${SCENARIO_RUNNER_ROOT}/* /tmp/scenario_runner/

          volumeMounts:
            - mountPath: /tmp/leaderboard
              name: leaderboard
            - mountPath: /tmp/scenario_runner
              name: scenario-runner

      containers:
        - name: monitor
          image.$: $.cluster.monitor_image
          command: ["/bin/bash", "-c"]
          args:
            - |
              bash /workspace/run_monitor.sh
          env:
            - name: SUBMISSION_ID
              value.$: $.submission.submission_id
            - name: SUBMISSION_WORKERS
              value.$: $.cluster.parallelization_workers
            - name: CHALLENGE_ID
              value.$: $.submission.challenge_id
            - name: TRACK_ID
              value.$: $.submission.track_id
            - name: TEAM_ID
              value.$: $.submission.team_id
            - name: S3_BUCKET
              value.$: "$.aws.s3_bucket"
            - name: DYNAMODB_SUBMISSIONS_TABLE
              value.$: "$.aws.dynamodb_submissions_table"
            - name: EVALAI_AUTH_TOKEN
              value.$: "$.evalai.auth_token"
            - name: EVALAI_API_SERVER
              value.$: "$.evalai.api_server"
          volumeMounts:
            - mountPath: /utils/leaderboard
              name: leaderboard
            - mountPath: /utils/scenario_runner
              name: scenario-runner
      restartPolicy: OnFailure
      volumes:
        - name: leaderboard
          emptyDir: {}
        - name: scenario-runner
          emptyDir: {}
